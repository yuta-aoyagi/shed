# 手計算で gzip/deflate を展開してみた動機と学び

先々週、数百バイトの gzip/deflate データを手計算で展開してみた:
https://x.com/yuuta_aoyagi/status/1868793102938652972
https://x.com/yuuta_aoyagi/status/1869153506026012735

今回 `gzip -c | base64` をかけてみたシェルスクリプトは複数あり、 ShellCheck の directive や `set -u` の設定をしている、先頭から百数十バイトはまったく同じである。
しかし出力の Base64 を見ると、 gzip のヘッダだろうと推測できる、ゼロのビットが連続した `A` の直後からビット列が大きく異なっていた。
この観察は「同じバイト列で始まる複数の入力を圧縮するなら、結果も同じビット列で始まるだろう」というナイーブな予想に反したため、その理由を知りたいというのが今回の動機である。

上でリンクした X のポストを書いていた時点で答えには気がついていて、ビット列に差が出始める領域は動的ハフマンコードの定義だった。
今回 gzip をかけた対象のファイルは数百バイトと小さいため、ファイル全体における各バイト値の出現頻度の差がハフマン符号に影響したわけだ。

ASCII 文字しか含まないシェルスクリプトが対象だったため、 MSB が立っているバイトは1つもなく、半角スペース(20h) の頻度が約1割、それに次いで `e` と `t` が多いという典型的な偏りが見られる。
今回は展開にあたって動的ハフマンコードの表を手計算したため内容を知っていて、半角スペースは3ビット、 `e` と `t` は4ビットのコードが割り当てられている。
すなわち、この3種のバイトは半分以下のビット数で表現されるわけだ。
コードの定義は今回は四十数バイトの大きさだったが、この増加を取り返して圧縮が効いたのはハフマン符号の威力だと言えるだろう。
